{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pendulum\n",
    "An Implementation of Reinforcement Learning\n",
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from math import pi\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from agent import DDPGAgent, DQNAgent, AssuredDQNAgent, JudgeAgent, TrigramJudgeAgent\n",
    "from environment import MAX_SPEED\n",
    "from framework import train, train_with_inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=\"WARNING\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent\n",
    "### Deep Deterministic Policy Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_ddpg = DDPGAgent(device)\n",
    "score_ddpg = train(agent_ddpg, \"DDPG\", num_episodes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_dqn = DQNAgent(device)\n",
    "score_dqn = train(agent_dqn, \"DQN\", num_episodes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_judge = JudgeAgent(device)\n",
    "score_judge = train_with_inspect(agent_judge, \"Judge\", num_episodes=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram Judge Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_trigram_judge = TrigramJudgeAgent(device)\n",
    "score_trigram_judge = train_with_inspect(agent_trigram_judge, \"TrigramJudge\", num_episodes=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN with Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_trigram = agent_trigram_judge.judge\n",
    "agent_dqn_penalty = AssuredDQNAgent(device)\n",
    "score_dqn_penalty = train_with_inspect(agent_dqn_penalty, \"DQN_Penalty\", num_episodes=10000, judge=judge_trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN with Barrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = agent_judge.judge\n",
    "agent_dqn_barrier = AssuredDQNAgent(device, judge=judge)\n",
    "score_dqn_barrier = train_with_inspect(agent_dqn_barrier, \"DQN_Barrier\", num_episodes=10000, judge=judge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN with Trigram Barrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_dqn_trigram_barrier = AssuredDQNAgent(device, judge=judge_trigram)\n",
    "score_dqn_trigram_barrier = train_with_inspect(agent_dqn_trigram_barrier, \"DQN_TrigramBarrier\", num_episodes=10000, judge=judge_trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"image\"):\n",
    "    os.mkdir(\"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta = torch.linspace(-pi, pi, 101)\n",
    "Omega = torch.linspace(-MAX_SPEED, MAX_SPEED, 65)\n",
    "X = torch.cos(Theta)\n",
    "Y = torch.sin(Theta)\n",
    "episodes = [9, 499, 999, 4999, 9999, 29999, 59999, 99999]\n",
    "fig, axes = plt.subplots(2, 5, figsize=(14, 6), gridspec_kw={'width_ratios':[1,1,1,1,0.08]})\n",
    "judge = JudgeAgent(device).judge\n",
    "for i in range(len(episodes)):\n",
    "    judge.load_state_dict(torch.load(f\"resource/Judge/{episodes[i]}.judge\"))\n",
    "    judge.eval()\n",
    "    data = {}\n",
    "    for theta in Theta:\n",
    "        states = torch.vstack([torch.cos(theta) * torch.ones(65), torch.sin(theta) * torch.ones(65), -Omega]).T.to(device)\n",
    "        ds = judge(states).cpu()\n",
    "        data[theta.item()] = torch.max(ds, axis=1).values.detach().numpy()\n",
    "    data = pd.DataFrame(data, index=(Omega).tolist())\n",
    "    if i % 4 == 3:\n",
    "        plot = sns.heatmap(data, ax=axes[i//4, 3], cbar_ax=axes[i//4, 4])\n",
    "    else:\n",
    "        plot = sns.heatmap(data, cbar=False, ax=axes[i//4, i%4])\n",
    "    if i % 4 == 0:\n",
    "        plot.set_ylabel(\"Angular Velocity\")\n",
    "    else:\n",
    "        plot.set_yticks([])\n",
    "    if i >= 4:\n",
    "        plot.set_xticks([0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "        plot.set_xticklabels(['$-\\pi$','$-4\\pi\\slash5$', '$-3\\pi\\slash5$', '$-2\\pi\\slash5$', '$-\\pi\\slash5$', '0', \n",
    "                              '$\\pi\\slash5$', '$2\\pi\\slash5$','$3\\pi\\slash5$', '$4\\pi\\slash5$', '$\\pi$'])\n",
    "        plot.set_xlabel(\"Angle to upright\")\n",
    "    else:\n",
    "        plot.set_xticks([])\n",
    "    plot.set_title(f\"Episode {episodes[i]}\")\n",
    "plt.savefig('image/judge_boundary.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram Judge Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(14, 6), gridspec_kw={'width_ratios':[1,1,1,1,0.08]})\n",
    "judge_trigram = TrigramJudgeAgent(device).judge\n",
    "for i in range(len(episodes)):\n",
    "    judge_trigram.load_state_dict(torch.load(f\"resource/TrigramJudge/{episodes[i]}.judge\"))\n",
    "    judge_trigram.eval()\n",
    "    data = {}\n",
    "    for theta in Theta:\n",
    "        states = torch.vstack([torch.cos(theta) * torch.ones(65), torch.sin(theta) * torch.ones(65), -Omega]).T.to(device)\n",
    "        ds = judge_trigram(states).cpu()\n",
    "        data[theta.item()] = torch.max(ds, axis=1).values.detach().numpy()\n",
    "    data = pd.DataFrame(data, index=(Omega).tolist())\n",
    "    if i % 4 == 3:\n",
    "        plot = sns.heatmap(data, ax=axes[i//4, 3], cbar_ax=axes[i//4, 4])\n",
    "    else:\n",
    "        plot = sns.heatmap(data, cbar=False, ax=axes[i//4, i%4])\n",
    "    if i % 4 == 0:\n",
    "        plot.set_ylabel(\"Angular Velocity\")\n",
    "    else:\n",
    "        plot.set_yticks([])\n",
    "    if i >= 4:\n",
    "        plot.set_xticks([0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "        plot.set_xticklabels(['$-\\pi$','$-4\\pi\\slash5$', '$-3\\pi\\slash5$', '$-2\\pi\\slash5$', '$-\\pi\\slash5$', '0', \n",
    "                              '$\\pi\\slash5$', '$2\\pi\\slash5$','$3\\pi\\slash5$', '$4\\pi\\slash5$', '$\\pi$'])\n",
    "        plot.set_xlabel(\"Angle to upright\")\n",
    "    else:\n",
    "        plot.set_xticks([])\n",
    "    plot.set_title(f\"Episode {episodes[i]}\")\n",
    "plt.savefig('image/trigram_judge_boundary.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Judge Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "axes[0].plot(score_judge.scores[\"Episode\"], score_judge.scores[\"Average Iteration from Safe Inits\"], 'b-', label='bigram')\n",
    "axes[0].plot(score_trigram_judge.scores[\"Episode\"], score_trigram_judge.scores[\"Average Iteration from Safe Inits\"], 'r-', label='trigram')\n",
    "axes[0].set_xlabel('Episode')\n",
    "axes[0].set_ylabel('Number of Iteration')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('Average Iteration from Safe Inits')\n",
    "axes[1].plot(score_judge.scores[\"Episode\"], score_judge.scores[\"Number of Safe Inits\"], 'b-', label='bigram')\n",
    "axes[1].plot(score_trigram_judge.scores[\"Episode\"], score_trigram_judge.scores[\"Number of Safe Inits\"], 'r-', label='trigram')\n",
    "axes[1].set_xlabel('Episode')\n",
    "axes[1].set_ylabel('Number of Safe Inits')\n",
    "axes[1].legend()\n",
    "axes[1].set_title('Number of Safe Inits')\n",
    "plt.savefig('image/comparison_of_judge_module.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Deep Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "axes[0].plot(score_dqn_penalty.scores[\"Episode\"], score_dqn_penalty.scores[\"Average Iteration from Safe Inits\"], 'b-', label='training with penalty\\ntrigram criterion')\n",
    "axes[0].plot(score_dqn_barrier.scores[\"Episode\"], score_dqn_barrier.scores[\"Average Iteration from Safe Inits\"], 'g-', label='training with barrier')\n",
    "axes[0].plot(score_dqn_trigram_barrier.scores[\"Episode\"], score_dqn_trigram_barrier.scores[\"Average Iteration from Safe Inits\"], 'r-', label='training with trigram barrier')\n",
    "axes[0].set_xlabel('Episode')\n",
    "axes[0].set_ylabel('Number of Iteration')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('Average Iteration from Safe Inits')\n",
    "axes[1].plot(score_dqn_penalty.scores[\"Episode\"], score_dqn_penalty.scores[\"Average Reward from Safe Inits\"], 'b-', label='training with penalty\\ntrigram criterion')\n",
    "axes[1].plot(score_dqn_barrier.scores[\"Episode\"], score_dqn_barrier.scores[\"Average Reward from Safe Inits\"], 'g-', label='training with barrier')\n",
    "axes[1].plot(score_dqn_trigram_barrier.scores[\"Episode\"], score_dqn_trigram_barrier.scores[\"Average Reward from Safe Inits\"], 'r-', label='training with trigram barrier')\n",
    "axes[1].set_xlabel('Episode')\n",
    "axes[1].set_ylabel('Average Discounted Reward')\n",
    "axes[1].legend()\n",
    "axes[1].set_title('Average Reward from Safe Inits')\n",
    "plt.savefig('image/comparison_of_deep_q_network.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c11202d2846b22eec7deaf37ea813ba92a5f75b5344a4d16688175855af7948e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
